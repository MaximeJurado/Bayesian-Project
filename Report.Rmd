---
title: "Salaries in the industry, trade and services in 2011"
author: "Maxime Jurado and Mathieu Marauri"
date: "Tuesday, May 26, 2015"
output:
  pdf_document:
    fig_caption: yes
    keep_tex: no
    number_sections: no
    toc: yes
header-includes: \usepackage{float} \usepackage{graphicx}
---


```{r initial_chunk, echo = FALSE, warning = FALSE, message = FALSE}
library("knitr")
library("ggplot2")
library("xtable")
library("dplyr")
library("gridExtra")
library("xtable")
opts_chunk$set(echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE)
options("xtable.comment" = FALSE)
options("xtable.table.placement" = "H")
```

```{r data}
data <- read.csv2("Data/data.csv",header=TRUE)
data <- subset(data,time!="TP")
data1 <- data[rep(1:nrow(data),each=5),]
data2 <- data.frame(data$X1,data$X2,data$X3,data$X4,data$X5)
data3 <- data.frame(data1$id,data1$time,data1$sexe)
vec <- NULL
for(i in 1:nrow(data2)){
  vec1 <- data2[i,]
  vec <- c(vec,t(vec1))
}
vec <- as.data.frame(vec)
data4 <- data.frame(data3,vec)
cat <- c(rep(c(1,2,3,4,5),132))
data <- data.frame(data4,cat)
colnames(data) <- c("id","time","sexe","salary","spc")
attach(data)
salary<-as.numeric(salary)
```

# Abstract

# Introduction

The structure of the salary in the industry, the services or the trade is a matter of importance in the society. It can reflects some inequalities, regarding the gender for instance, or some tendencies. The aim of this study is to analyse the effect of several indicators such as the Socio-Professional Category or the gender on the salary. 

Performing such an analysis on data coming from France is for us really interesting because we have several preconceptions about the impact of the gender for example. Studying those data will allow us to either confirm or deny these preconceptions. 

By performing Bayesian models the effects of the indicators will be known. Those effects will be quantified. It will provide useful knowledge on the structure of the salary. 

# Dataset
\label{dataset}

The dataset comes from the *Institut National de la Statistique et des Etudes Economiques* or INSEE in France. It is the statistical institute of France. The dataset contains 33 sectors of activity that are identified by the *id* variable. The classification can be found in table \ref{tableIndexSectors}. 

The variables reported in this study are listed below:

* Time is an indicator which takes value 1 for a full-time work and 0 for a part-time work. _time_
* Sexe is a binary variable with value 1 for male and 0 for female. _sexe_
* Socio-Professional Category: it takes values between 1 and 5. Table \ref{tableIndexSpc} shows the classification. _spc_
* Salary: it is the response variable. _salary_

The salary is the average gross income for an hour. For instance it can be the average income of female employees working full-time in the extraction industry.

In the original dataset there were a cell by combination of the different variables. It was built so that no cell contains less than 5 entries and that no entry would represent more than 80% of the total. Some data are missing due to statistical privacy. It is the case for the id 8 which is the sector of Transportation equipment manufacture.


# Statistical methods

In this study several Bayesian models will be performed, first a Gaussian Bayesian model then a hierarchical Bayesian model. In both cases covariateswill be add to an initial model and by comparing the Deviance Information Criterion or DIC. Since a model with more parameters will always be preferrable to a "simpler" one, parsimony will also be used to select the best model. The goal is to have the best model but also the one that is 

## Gaussian Bayesian regression

In the Gassian Bayesian model the point is to get the mean effect of the covariates on the salary. By performing such a model one wants to know how the covariates impact the salary. Among the different models that can be performed the best one will be used as the initial model in the hierarchical Bayesian models selection. The Gaussian Bayesian model is of this form:

TODO b2
\begin{centering}

  $Y|X ~ N(\beta X,\tau_1)$
  
  $\Pi(\beta) ~ N(\mu,\tau_2)$
  
  $\Pi(\tau_1) ~ Gamma(a,b)$

\end{centering}

The parameter $\beta$ is a vector and X is the matrix of the covaiates. The statistical model Gaussian with a linear expression of the covarites and the intercept as a mean and a variance of $\tau_1$. $\beta$ also follows a Gaussian distribution. Finally $\tau_2$ follows a Gamma with parameters a and b that are fixed to 0.01.

## Gaussian hierarchical Bayesian regression

A hierarchical Bayesian model is a model with random effects. Those random effects allow the model to add variance to the estimtates of the parameters of the covariates. It means that each sector has different values for the estimates of the covariates. This way each sector has more precise estimates and it is possible to see the differences between sectors. 

The initial model is the Gaussian Bayesian model that was selected. Then random effects are added to this model and the best model is selected based on the same selection process than before. 


The Gaussian hierarchical model is designed as follow:

\begin{centering}

  $Y|X ~ N(\beta X+b_i X_r,\tau_1)$
  
  $\Pi(\beta) ~ N(\mu,\tau_2)$
  
  $b_i ~N(0,\tau_{3,i})$
  
  $\Pi(\tau_1) ~ Gamma(a_1,b_1)$
  
  $\Pi(\tau_{3,i}) ~ Gamma(a_2,b_2)$

\end{centering}

As previously X is a matrix of the covariate and $X_r$ is also a matrix of the covariate but it may be different from X since random effects can be added on different covariates. Again as before $a_1, b_1, a_2 and b_2$ ae all equal to 0.01.  


# Descriptive analysis

An exploration of the data through a descriptive analysis gives first insights on the behavior of the variables. The point here is to see graphically if some variables seem to have an impact on the response variable, the salary. A basic linear regression and some tests give also some insights.

## Influence of the variable _spc_

The first idea is that the salary is supposed to be different based on the different Socio-Professional Categories. The following graph (Figure \ref{BoxplotCat}) shows the mean of the salary by SPC.
```{r boxplotcat, fig.cap="Boxplot of the salary for each category. \\label{BoxplotCat}", fig.pos="H", fig.align='left'}
theme <- theme(plot.title = element_text(size=10, face="bold"), axis.title.x = element_text(size=10), axis.title.y = element_text(size=10), axis.text.x = element_text(size=10, face="bold"),axis.text.y = element_text(size=10, face="bold"))
ggplot(data, aes(factor(spc), salary)) + geom_boxplot(aes(fill = factor(spc))) + xlab("Socio-Professional Category") + ylab("Salary") + guides(fill=guide_legend(title=NULL)) + theme
```

One can clearly see that being in the category 1 (Higher managerial and professional positions) increases the salary as compared to the other categories. If one considers the categories to be ordered from 1 to 5 then he would be able to say that _SPC_ seems to have a negative impact on the salary.

In order to see more clearly the way _SPC_ influences the salary Figure \ref{completeplot} shows the evolution of the salary for each SPC for each sector. The means were calculated on all the values of salary for the SPC by id.
```{r completeplot, fig.cap="Evolution of the salary for each SPC by id. \\label{completeplot}", fig.pos="H", fig.align='left'}
datamean <- aggregate(data.frame(salaryMean = data$salary), by = list(id = data$id, spc = data$spc),mean)
ggplot(datamean, aes(spc, salaryMean)) + facet_wrap(facets=~ id, ncol=10) + geom_line(colour="blue") + geom_point(colour="red") + theme
```

As seen previously _SPC_ seems to have a negative impact on the salary for every sectors but sector 6 (Manufacture of food, drink and tobacco based products), sector 21 (Information and communication) and sector 30 (Arts and entertainment). This may be due to the definitions of the SPC. In most of the sectors they are ordered from 1 to 5 but in some other sectors this order can be different. 

TODO spc2

## Influence of the variable _time_

The salary is given per hour, hence no differences between full-time and part-time jobs should be observed. The following figure confirms this.
```{r boxplottime, fig.cap="Boxplot of the salary for each time. \\label{boxplottime}", fig.pos="H", fig.align='left'}
ggplot(data, aes(factor(time), salary)) + geom_boxplot(aes(fill = factor(time))) + labs(x="Time", y="Salary") + theme + scale_fill_manual(name="Time", values=c("orange", "mediumpurple"), labels=c("0"="Part-time", "1"="Full-time"))
```

The salaries for the full-time workers ant the salaries for the part-time workers seem to be the same. 

The same graph was repeated for each category and the following results were obtained. Figure \ref{boxplotspctime}.
```{r boxplotspctime, fig.cap="Boxplot of the salary for each SPC and each time. \\label{boxplotspctime}", fig.pos="H", fig.align='left'}
ggplot(data, aes(factor(spc), salary)) + geom_boxplot(aes(fill = factor(time))) + labs(x="SPC", y="Salary") + theme + scale_fill_manual(name="Time", values=c("orange", "mediumpurple"), labels=c("0"="Part-time", "1"="Full-time"))
```

One could say that for some categories a small difference is observed. For instance salaries for full-time workers in the category of the higher managerial and professional positions seem to be higher than the ones for the part-time workers.

A t-test was performed to see if there is a difference between the salaries of full-time workers and part-time workers. This test was performed on the whole dataset and then by category. Table \ref{tabletesttime} shows the results.

\begin{table}[ht]
\centering
\begin{tabular}{ccc}
  \hline
 & p-value & mean of the differences \\ 
  \hline
 dataset & 0.000 & -0.788 \\ 
 category 1 & 0.000 & -1.982 \\ 
 category 2 & 0.298 & -0.277 \\ 
 category 3 & 0.000 & -1.027 \\ 
 category 4 & 0.316 & -0.188 \\ 
 category 5 & 0.051 & -0.427 \\ 
   \hline
\end{tabular}
\caption{P-values and mean of the differences 
             of the tests. \label{tabletesttime}} 
\end{table}

One can see that the p-values for the tests performed on the whole dataset, on the category 1 and on the category 3 are below 0.05. In those cases the mean of the differences can be up to almost 2 euros per hour. It represents a difference of 6.2%. 

## Influence of the variable _sexe_

TODO: legend is too big

Inequality in the salary regarding the gender is a matter of discussion in France. The issue is that salaries are said to be higher for males than they are for females. Therefore some differences are expected.

The means of the salaries for females and males were plotted for each Socio-Professional Category and it seems that no differences appear except maybe for the category 1. Figure \ref{barplotsexespc} shows the results.
```{r barplotsexespc, fig.cap="Barplot of the mean salary by sexe for each category. \\label{barplotsexespc}", fig.pos="H", fig.align='left'}
data.m <- aggregate(data.frame(salary.m = data$salary), by = list(sexe = data$sexe, spc = data$spc,time = data$time), mean, na.rm=TRUE)
ggplot(data.m,aes(x=factor(sexe),y=salary.m,fill=factor(sexe))) + geom_bar(stat = "identity") + facet_wrap(~ spc) + labs(x="Sexe", y="Mean salary") +scale_fill_discrete(name="Gender",  labels=c("Female", "Male"),guide = guide_legend(reverse=TRUE)) + theme(plot.title = element_text(size=16, face="bold"), legend.title = element_text(colour="black",size=18, face="bold"),legend.position=c(.85,.15),legend.background = element_rect(size=25),legend.text = element_text(size = 16))
```

For every categories the mean salary for males seems to be higher than the mean salary for females. A t-test confirmed this result. A significant mean of the differences of 2 was observed. It means that males have in mean a salary per hour higher by 2 euros than the one of the females.

## A linear regression

A basic linear regression was performed to see the impact of the covariates on the salary. The model that was used is:
  $Salary = \beta_0 + \beta_1time + \beta_2sexe +\beta_3spc + \beta_4sexe*spc + \beta_4*spc^2$

The following table (Table \ref{tablereg}) shows the estimates and the p-values obtained with the linear regression model.

```{r reg, results='asis'}
data.spc2 <- cbind(data,data$spc^2)
colnames(data.spc2) <- c("id","time","sexe","salary","spc","spc²")
reg.spc2 <- lm(salary~time+sexe*spc+spc², data=data.spc2)
table.reg <- data.frame(coefficients(reg.spc2),summary(reg.spc2)[[4]][,4])
colnames(table.reg) <- c("estimates","p-value")
print(xtable(table.reg, digits=3, align=c("c","c","c"),caption="Results of the linear regression. \\label{tablereg}"))
```

As for the graphical analysis _spc_ has a negative impact on the salary (we consider here that the categories are ordered from 1 to 5). The variable _sexe_ has a quite important positive effect on the salary. It means that males are paid around 4 euros per hour more than females. The fact that the interaction between _sexe_ and _spc_ has a negative effect on the salary means that the positive effect of being a male does not counterbalance the negative impact of the _spc_. Finally _time_ has a small positive impact. It means that when you work in a full-time job, you earn around 0.8 euros more than a part-time job.


# Gaussian Bayesian model 

```{r bug}
library(R2WinBUGS)
path.bug <- "C:/Users/Maxime/Desktop/Cours ERASMUS/Bayesian Analysis/Project/Bayesian-Project/modelBug/"
path.WBS <- "C:/Users/Maxime/Desktop/Cours ERASMUS/Bayesian Analysis/Project/Bayesian-Project/winbugs14/WinBUGS14/"

Iter <- 1000
Burn <- 500
Chain <- 2
Thin <- 1
n <- nrow(data)
datalist <- list(salary=data$salary, time=data$time, sexe=data$sexe, spc=data$spc, n=n)
datalist2 <- list(salary=data$salary,time=data$time, sexe=data$sexe, spc=data$spc, spc2=(data$spc)^2, n=n)
```

Before going trough the interpretation of a Bayesian Gaussian Regression, we have to choose which model is the best. For that we start with a simple model with three covariate: _time_, _sexe_ and _spc_. Then we tried to add _$spc^2$_ as explained in the descriptive part. Finally we try to add some interaction between covariates. To decide which model is the best, we use the DIC criteria and the error from the prediction.
The results are presented below

TABLE HERE

As you can see, the best model is the one with _$spc^2$_ and the interaction between _spc_ and _sexe_. However the sum of squares is still big. It means that our model does not predict well the future values. That is why we try to add some random effects in the next part. Now we have selected the model, we can go to the interpretation.


```{r model}
parameters13 <- c("alpha", "beta1", "beta2", "beta3","beta4","beta5", "tau", "mu")
inits13 <- list(list(tau=1), list(tau=5))
model13 <- bugs(datalist2, inits=inits13, parameters.to.save=parameters13,model=paste(path.bug,"modelWin13.bug",sep=""),bugs.directory=path.WBS,n.iter=(Iter*Thin+Burn),n.burnin=Burn, n.thin=Thin, n.chains=Chain, DIC=T, debug=T)
```

In table \ref{resultsmodel} we can see the results of the Bayesian Gaussian Regression that we choose above. The coefficients are very similar to those obtained in the descriptive part. Thus the interpretation is the same as in \refname{A linear regression}. We still have this negative impact of _spc_ and the interaction between _sexe_ and _spc_. We also find again the positive impact of _sexe_ that does not counterbalance the effect of _spc_. Finally the impact of _time_ is still positive.

```{r resultsmodel, results='asis'}
results <- t(as.data.frame(c(model13$mean[1],model13$mean[2],model13$mean[3],model13$mean[4],
             model13$mean[5],model13$mean[6])))
colnames(results) <- c("mean")
rownames(results) <- c("intercept", "time", "sexe", "spc", "spc*sexe", "spc²")
print(xtable(results, digits=4, align=c("c","c"), caption="Mean for the Bayesian model. \\label{resultsmodel}"))
```


# Gaussian hierarchical Bayesian model

As for the Bayesian Gaussian Regression, we have to choose here the best model. We proceed the same way, trying to ass random effects to one covariate at a time. But at the end, we do not want to overparametrize the model, that is why we limit this study to 2 random effects maximum.

TABLE HERE

You can see that the model with random effects on the _Intercept_ and _sexe_ is the best. Furthermore, the sum of squares is lower than in the Bayesian Gaussian Regression. This is our final model. 

```{r model2}
parameters221 <- c("alpha", "beta1", "beta2", "beta3","beta4","beta5", "tau","tau2", "tau3", "mu")
inits221 <- list(list(tau=1,tau2=1, tau3=1), list(tau=2,tau2=2, tau3=2))
model221 <- bugs(datalist2, inits=inits221, parameters.to.save=parameters221,model=paste(path.bug,"modelWin221.bug",sep=""),bugs.directory=path.WBS,n.iter=(Iter*Thin+Burn),n.burnin=Burn, n.thin=Thin, n.chains=Chain, DIC=T, debug=T)
```

In table \ref{resultsmodel2}, the coefficients of our final model are presented. It can be seen that they do not differ a lot from the previous interpretations. The main part here is the random effects on _Intercept_ and _sexe_. It means that we add variability for each subject. We can observe differences of each sector. But here, the variance added by the random effects does not the effect of a covariate. The sign of its coefficient will not change. The global effect will be the same.


```{r resultsmodel2, results='asis'}
results2 <- t(as.data.frame(c(model221$mean[1],model221$mean[2],model221$mean[3],model221$mean[4],
                             model221$mean[5],model221$mean[6])))
colnames(results2) <- c("mean")
rownames(results2) <- c("intercept", "time", "sexe", "spc", "spc*sexe", "spc²")
print(xtable(results2, digits=4, align=c("c","c"), caption="Mean for the hierarchical model. \\label{resultsmodel2}"))
```


# Conclusion

TODO further analysis
TODO difficulties encountered

# Bibliography

* [INSEE T101 Salaire brut horaire, par âge et catégorie socioprofessionnelle simplifiée](http://www.insee.fr/fr/themes/detail.asp?reg_id=0&ref_id=ir-irsocdads2011&page=irweb/irsocdads2011/dd/irsocdads2011_t10.htm)
* [Introduction fo WinBUGS](http://homepage.stat.uiowa.edu/~gwoodwor/BBIText/AppendixBWinbugs.pdf)
* [WinBUGS Training](https://www.uclouvain.be/cps/ucl/doc/stat/documents/WinBUGSTraining_smcs.pdf)


# Appendix

## Classification tables

Here are presented the classification tables for the Socio-Professional Categories (Table \ref{tableIndexSpc}) and for the Sectors (Table \ref{tableIndexSectors}).

```{r classification table spc, results='asis'}
categories <- read.table("Data/Index SCP.txt", sep="-", header=FALSE)
categories <- data.frame(categories$V2)
colnames(categories) <- "Category"
print(xtable(categories, align=c("c","c"), caption="Classification table of the Socio-Professional Categories. \\label{tableIndexSpc}"))
```

```{r classification table sectors, results='asis'}
sectors <- read.table("Data/Index Sectors.txt", sep=";", header=FALSE)
sectors <- data.frame(sectors$V2)
colnames(sectors) <- "Sector"
print(xtable(sectors, align=c("c","c"), caption="Classification table of the Sectors. \\label{tableIndexSectors}"))
```

Return to section \nameref{dataset}.

## Code